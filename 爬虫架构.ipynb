{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 网络爬虫基本架构实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "newsurl = 'https://news.qq.com/'\n",
    "res = requests.get(newsurl)\n",
    "#print(res.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Hello World This is link1 This is link2  '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "html_sample = '\\\n",
    "<html> \\\n",
    " <body> \\\n",
    " <h1 id=\"title\">Hello World</h1> \\\n",
    "<a href=\"#\" class=\"link\">This is link1</a> \\\n",
    "<a href=\"# link2\" class=\"link\">This is link2</a> \\\n",
    " </body> \\\n",
    " <html>'\n",
    "soup = BeautifulSoup(html_sample,'html.parser')\n",
    "soup.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用select提取特定标签下的元素，返回结果是list，需要进行进一步的操作取得标签里的文字。\n",
    "soup.select('h1')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is link2'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('a')[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is link1\n",
      "This is link2\n"
     ]
    }
   ],
   "source": [
    "for alink in soup.select('a'):\n",
    "    print(alink.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#根据CSS提取网页中的文字内容\n",
    "soup.select('#title')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is link1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.select('.link')[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#\n",
      "# link2\n"
     ]
    }
   ],
   "source": [
    "#提取a标签的目标网页href中的网址\n",
    "for link in soup.select('a'):\n",
    "    print(link['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "欧冠16强抽签：皇马对决曼城 利物浦PK马竞\n",
      "=======================\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "newsurl = 'https://sports.qq.com/'\n",
    "res = requests.get(newsurl)\n",
    "#print(res.text)\n",
    "soup = BeautifulSoup(res.text,'html.parser')\n",
    "for news in soup.select('.scr-news'):\n",
    "    print(news.select('a')[0].text)\n",
    "    print('=======================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "newsurl = 'https://sports.qq.com/'\n",
    "res = requests.get(newsurl)\n",
    "#print(res.text)\n",
    "soup = BeautifulSoup(res.text,'html.parser')\n",
    "\n",
    "newsarray=[]\n",
    "\n",
    "for news in soup.select('.scr-news'):\n",
    "    newsarray.append({'title':news.text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>\\n\\n\\n\\n\\n欧冠16强抽签：皇马对决曼城 利物浦PK马竞\\n欧联杯32强抽签：武磊遭...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title\n",
       "0  \\n\\n\\n\\n\\n欧冠16强抽签：皇马对决曼城 利物浦PK马竞\\n欧联杯32强抽签：武磊遭..."
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "newsdf = pd.DataFrame(data=newsarray)\n",
    "newsdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsdf.to_csv('news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
